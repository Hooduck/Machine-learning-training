{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111258\n",
      "477\n",
      "nb of empl. = 146\n",
      "nb of field/empl. = 21\n",
      "nb of poi = 18\n",
      "James Prentice / total stock value =  1.1 M$\n",
      "Wesley Colwell / from this person to poi =  11 mails\n",
      "Jeffrey K Skilling / exercised stock options =  19.25 M$\n",
      "nb of empl. with salary = 95/146, nb of empl. with email adress = 111/146\n",
      "nb of empl. without To. pay. data = 21, %age = 14.38%\n",
      "nb of POI without To. pay. data = 0, %age = 0.0%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Starter code for exploring the Enron dataset (emails + finances);\n",
    "    loads up the dataset (pickled dict of dicts).\n",
    "\n",
    "    The dataset has the form:\n",
    "    enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "\n",
    "    {features_dict} is a dictionary of features associated with that person.\n",
    "    You should explore features_dict as part of the mini-project,\n",
    "    but here's an example to get you started:\n",
    "\n",
    "    enron_data[\"SKILLING JEFFREY K\"][\"bonus\"] = 5600000\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import pprint as pp\n",
    "from poi_email_addresses import poiEmails\n",
    "import operator\n",
    "\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        import math\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "poi_emails = poiEmails()\n",
    "\n",
    "with open(\"../final_project/final_project_dataset.pkl\", \"r\") as f:\n",
    "    enron_data = pickle.load(f)\n",
    "    \n",
    "    poi = set()\n",
    "    for empl in enron_data:\n",
    "        if enron_data[empl]['poi'] == True:poi.add(empl)\n",
    "    \n",
    "    \n",
    "    top_of_asshole = dict()\n",
    "    hided_bitches = dict()\n",
    "    hided_bitches_and_POI = dict()\n",
    "    for asshole in enron_data:\n",
    "        if not isnan(enron_data[asshole]['total_payments']):\n",
    "            top_of_asshole[asshole] = (enron_data[asshole]['total_payments'],\\\n",
    "                                       enron_data[asshole]['salary'], enron_data[asshole]['bonus'])\n",
    "        elif enron_data[asshole]['poi'] == True:\n",
    "            hided_bitches[asshole] = enron_data[asshole]['total_payments']\n",
    "            hided_bitches_and_POI[asshole] = enron_data[asshole]['poi']\n",
    "        else: hided_bitches[asshole] = enron_data[asshole]['total_payments']\n",
    "    top_of_asshole = sorted(top_of_asshole.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    max_value = dict()\n",
    "    key_mv = 'salary'\n",
    "    for asshole in enron_data:\n",
    "        if not isnan(enron_data[asshole][key_mv]):\n",
    "            max_value[asshole] = enron_data[asshole][key_mv]\n",
    "    max_value.pop('TOTAL')\n",
    "    print max(max_value.values())\n",
    "    print min(max_value.values())\n",
    "    \n",
    "    \n",
    "    salary = dict()\n",
    "    mail = dict()\n",
    "    for empl in enron_data:\n",
    "        if not isnan(enron_data[empl]['salary']):\n",
    "            salary[empl] = enron_data[empl]['salary']\n",
    "        if not isnan(enron_data[empl]['email_address']):\n",
    "            mail[empl] = enron_data[empl]['email_address']\n",
    "    salary = sorted(salary.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    print \"nb of empl. =\", len(enron_data)\n",
    "    print \"nb of field/empl. =\", len(enron_data['LAY KENNETH L'])\n",
    "    print \"nb of poi =\", len(poi)\n",
    "    print \"James Prentice / total stock value = \",\\\n",
    "        round(enron_data['PRENTICE JAMES']['total_stock_value'] / 10**6., 2), \"M$\"\n",
    "    print \"Wesley Colwell / from this person to poi = \",\\\n",
    "        enron_data['COLWELL WESLEY']['from_this_person_to_poi'], \"mails\"\n",
    "    print \"Jeffrey K Skilling / exercised stock options = \",\\\n",
    "        round(enron_data['SKILLING JEFFREY K']['exercised_stock_options'] / 10**6., 2), \"M$\"\n",
    "    print \"nb of empl. with salary = {}/{}, nb of empl. with email adress = {}/{}\"\\\n",
    "        .format(len(salary), len(enron_data), len(mail), len(enron_data))\n",
    "    print \"nb of empl. without To. pay. data = {}, %age = {}%\"\\\n",
    "        .format(len(hided_bitches), round((float(len(hided_bitches))/len(enron_data))*100, 2))\n",
    "    print \"nb of POI without To. pay. data = {}, %age = {}%\"\\\n",
    "        .format(len(hided_bitches_and_POI), round((float(len(hided_bitches_and_POI))/len(enron_data))*100, 2))\n",
    "    \n",
    "    \n",
    "    #pp.pprint(max_value)\n",
    "    #pp.pprint(hided_bitches_and_POI)\n",
    "    #pp.pprint(enron_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PAS ENCORE UTILISE A VOIR EN LECON 7\n",
    "\n",
    "\"\"\" \n",
    "    A general tool for converting data from the\n",
    "    dictionary format to an (n x k) python list that's \n",
    "    ready for training an sklearn algorithm\n",
    "\n",
    "    n--no. of key-value pairs in dictonary\n",
    "    k--no. of features being extracted\n",
    "\n",
    "    dictionary keys are names of persons in dataset\n",
    "    dictionary values are dictionaries, where each\n",
    "        key-value pair in the dict is the name\n",
    "        of a feature, and its value for that person\n",
    "\n",
    "    In addition to converting a dictionary to a numpy \n",
    "    array, you may want to separate the labels from the\n",
    "    features--this is what targetFeatureSplit is for\n",
    "\n",
    "    so, if you want to have the poi label as the target,\n",
    "    and the features you want to use are the person's\n",
    "    salary and bonus, here's what you would do:\n",
    "\n",
    "    feature_list = [\"poi\", \"salary\", \"bonus\"] \n",
    "    data_array = featureFormat( data_dictionary, feature_list )\n",
    "    label, features = targetFeatureSplit(data_array)\n",
    "\n",
    "    the line above (targetFeatureSplit) assumes that the\n",
    "    label is the _first_ item in feature_list--very important\n",
    "    that poi is listed first!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True,\\\n",
    "                    remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "\n",
    "        return targets and features as separate lists\n",
    "\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
