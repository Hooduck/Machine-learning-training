{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb of empl. = 146\n",
      "nb of field/empl. = 21\n",
      "nb of poi = 18\n",
      "James Prentice / total stock value =  1.1 M$\n",
      "Wesley Colwell / from this person to poi =  11 mails\n",
      "Jeffrey K Skilling / exercised stock options =  19.25 M$\n",
      "nb of empl. with salary = 95/146, nb of empl. with email adress = 111/146\n",
      "nb of empl. without To. pay. data = 21, %age = 14.38%\n",
      "nb of POI without To. pay. data = 0, %age = 0.0%\n",
      "[('TOTAL', (309886585, 26704229, 97343619)),\n",
      " ('LAY KENNETH L', (103559793, 1072321, 7000000)),\n",
      " ('FREVERT MARK A', (17252530, 1060932, 2000000)),\n",
      " ('BHATNAGAR SANJAY', (15456290, 'NaN', 'NaN')),\n",
      " ('LAVORATO JOHN J', (10425757, 339288, 8000000)),\n",
      " ('SKILLING JEFFREY K', (8682716, 1111258, 5600000)),\n",
      " ('MARTIN AMANDA K', (8407016, 349487, 'NaN')),\n",
      " ('BAXTER JOHN C', (5634343, 267102, 1200000)),\n",
      " ('BELDEN TIMOTHY N', (5501630, 213999, 5249999)),\n",
      " ('DELAINEY DAVID W', (4747979, 365163, 3000000)),\n",
      " ('WHALLEY LAWRENCE G', (4677574, 510364, 3000000)),\n",
      " ('ALLEN PHILLIP K', (4484442, 201955, 4175000)),\n",
      " ('SHERRIFF JOHN R', (4335388, 428780, 1500000)),\n",
      " ('MCMAHON JEFFREY', (4099771, 370448, 2600000)),\n",
      " ('HAEDICKE MARK E', (3859065, 374125, 1150000)),\n",
      " ('FALLON JAMES B', (3676340, 304588, 2500000)),\n",
      " ('KITCHEN LOUISE', (3471141, 271442, 3100000)),\n",
      " ('MULLER MARK S', (3202070, 251654, 1100000)),\n",
      " ('HORTON STANLEY C', (3131860, 'NaN', 'NaN')),\n",
      " ('PAI LOU L', (3123383, 261879, 1000000)),\n",
      " ('HUMPHREY GENE E', (3100224, 130724, 'NaN')),\n",
      " ('SHANKMAN JEFFREY A', (3038702, 304110, 2000000)),\n",
      " ('ECHOLS JOHN B', (2692324, 182245, 200000)),\n",
      " ('BOWEN JR RAYMOND M', (2669589, 278601, 1350000)),\n",
      " ('LEFF DANIEL P', (2664228, 273746, 1000000)),\n",
      " ('KOPPER MICHAEL J', (2652612, 224305, 800000)),\n",
      " ('FASTOW ANDREW S', (2424083, 440698, 1300000)),\n",
      " ('DIMICHELE RICHARD G', (2368151, 262788, 1000000)),\n",
      " ('BUY RICHARD B', (2355702, 330546, 900000)),\n",
      " ('GOLD JOSEPH', (2146973, 272880, 750000)),\n",
      " ('MCCONNELL MICHAEL S', (2101364, 365038, 1100000)),\n",
      " ('DURAN WILLIAM D', (2093263, 210692, 750000)),\n",
      " ('HICKERSON GARY J', (2081796, 211788, 1700000)),\n",
      " ('BIBI PHILIPPE A', (2047593, 213625, 1000000)),\n",
      " ('BLACHMAN JEREMY M', (2014835, 248546, 850000)),\n",
      " ('SHELBY REX', (2003885, 211844, 200000)),\n",
      " ('IZZO LAWRENCE L', (1979596, 85274, 'NaN')),\n",
      " ('WHITE JR THOMAS E', (1934359, 317543, 450000)),\n",
      " ('CAUSEY RICHARD A', (1868758, 415189, 1000000)),\n",
      " ('MEYER ROCKFORD G', (1848227, 'NaN', 'NaN')),\n",
      " ('WALLS JR ROBERT H', (1798780, 357091, 850000)),\n",
      " ('KEAN STEVEN J', (1747522, 404338, 1000000)),\n",
      " ('PIPER GREGORY F', (1737629, 197091, 400000)),\n",
      " ('CALGER CHRISTOPHER F', (1639297, 240189, 1250000)),\n",
      " ('KOENIG MARK E', (1587421, 309946, 700000)),\n",
      " ('SHARP VICTORIA T', (1576511, 248146, 600000)),\n",
      " ('GARLAND C KEVIN', (1566469, 231946, 850000)),\n",
      " ('SUNDE MARTIN', (1545059, 257486, 700000)),\n",
      " ('COLWELL WESLEY', (1490344, 288542, 1200000)),\n",
      " ('FITZGERALD JAY L', (1414857, 199157, 350000)),\n",
      " ('DIETRICH JANET R', (1410464, 250100, 600000)),\n",
      " ('PICKERING MARK R', (1386690, 655037, 300000)),\n",
      " ('OLSON CINDY K', (1321557, 329078, 750000)),\n",
      " ('MCCLELLAN GEORGE', (1318763, 263413, 900000)),\n",
      " ('HERMANN ROBERT J', (1297461, 262663, 700000)),\n",
      " ('GLISAN JR BEN F', (1272284, 274975, 600000)),\n",
      " ('BUTTS ROBERT H', (1271582, 261516, 750000)),\n",
      " ('DEFFNER JOSEPH M', (1208649, 206121, 600000)),\n",
      " ('DETMERING TIMOTHY J', (1204583, 210500, 425000)),\n",
      " ('GRAY RODNEY', (1146658, 6615, 'NaN')),\n",
      " ('UMANOFF ADAM S', (1130461, 288589, 788750)),\n",
      " ('STABLER FRANK', (1112087, 239502, 500000)),\n",
      " ('COX DAVID', (1101393, 314288, 800000)),\n",
      " ('RIEKER PAULA H', (1099100, 249201, 700000)),\n",
      " ('TAYLOR MITCHELL S', (1092663, 265214, 600000)),\n",
      " ('KAMINSKI WINCENTY J', (1086821, 275101, 400000)),\n",
      " ('METTS MARK', (1061827, 365788, 600000)),\n",
      " ('SHAPIRO RICHARD S', (1057548, 269076, 650000)),\n",
      " ('BUCHANAN HAROLD G', (1054637, 248017, 500000)),\n",
      " ('WASAFF GEORGE', (1034395, 259996, 325000)),\n",
      " ('SULLIVAN-SHAKLOVITZ COLLEEN', (999356, 162779, 100000)),\n",
      " ('BECK SALLY W', (969068, 231330, 700000)),\n",
      " ('GIBBS DANA R', (966522, 'NaN', 'NaN')),\n",
      " ('BANNANTINE JAMES M', (916197, 477, 'NaN')),\n",
      " ('THORN TERENCE H', (911453, 222093, 'NaN')),\n",
      " ('GAHN ROBERT S', (900585, 192008, 509870)),\n",
      " ('LINDHOLM TOD A', (875889, 236457, 200000)),\n",
      " ('DONAHUE JR JEFFREY M', (875760, 278601, 800000)),\n",
      " ('BAZELIDES PHILIP J', (860136, 80818, 'NaN')),\n",
      " ('BAY FRANKLIN R', (827696, 239671, 400000)),\n",
      " ('MURRAY JULIA H', (812194, 229284, 400000)),\n",
      " ('CUMBERLAND MICHAEL S', (807956, 184899, 325000)),\n",
      " ('NOLES JAMES L', (774401, 'NaN', 'NaN')),\n",
      " ('WESTFAHL RICHARD K', (762135, 63744, 'NaN')),\n",
      " ('KISHKILL JOSEPH G', (704896, 174246, 'NaN')),\n",
      " ('MORDAUNT KRISTINA M', (628522, 267093, 325000)),\n",
      " ('BERGSIEKER RICHARD P', (618850, 187922, 250000)),\n",
      " ('PRENTICE JAMES', (564348, 'NaN', 'NaN')),\n",
      " ('JACKSON CHARLENE R', (551174, 288558, 250000)),\n",
      " ('DERRICK JR. JAMES V', (550981, 492375, 800000)),\n",
      " ('RICE KENNETH D', (505050, 420636, 1750000)),\n",
      " ('CARTER REBECCA C', (477557, 261809, 300000)),\n",
      " ('TILNEY ELIZABETH A', (399393, 247338, 300000)),\n",
      " ('REYNOLDS LAWRENCE', (394475, 76399, 100000)),\n",
      " ('THE TRAVEL AGENCY IN THE PARK', (362096, 'NaN', 'NaN')),\n",
      " ('YEAGER F SCOTT', (360300, 158403, 'NaN')),\n",
      " ('DODSON KEITH', (319941, 221003, 70000)),\n",
      " ('HANNON KEVIN P', (288682, 243293, 1500000)),\n",
      " ('OVERDYKE JR JERE C', (249787, 94941, 'NaN')),\n",
      " ('URQUHART JOHN A', (228656, 'NaN', 'NaN')),\n",
      " ('BERBERIAN DAVID', (228474, 216582, 'NaN')),\n",
      " ('WAKEHAM JOHN', (213071, 'NaN', 'NaN')),\n",
      " ('ELLIOTT STEVEN', (211725, 170941, 350000)),\n",
      " ('WODRASKA JOHN', (189583, 'NaN', 'NaN')),\n",
      " ('BADUM JAMES P', (182466, 'NaN', 'NaN')),\n",
      " ('FOY JOE', (181755, 'NaN', 'NaN')),\n",
      " ('GRAMM WENDY L', (119292, 'NaN', 'NaN')),\n",
      " ('REDMOND BRIAN L', (111529, 96840, 'NaN')),\n",
      " ('BELFER ROBERT', (102500, 'NaN', 'NaN')),\n",
      " ('HIRKO JOSEPH', (91093, 'NaN', 'NaN')),\n",
      " ('LEMAISTRE CHARLES', (87492, 'NaN', 'NaN')),\n",
      " ('WALTERS GARETH W', (87410, 'NaN', 'NaN')),\n",
      " ('WINOKUR JR. HERBERT S', (84992, 'NaN', 'NaN')),\n",
      " ('JAEDICKE ROBERT', (83750, 'NaN', 'NaN')),\n",
      " ('DUNCAN JOHN H', (77492, 'NaN', 'NaN')),\n",
      " ('YEAP SOON', (55097, 'NaN', 'NaN')),\n",
      " ('FUGH JOHN L', (50591, 'NaN', 'NaN')),\n",
      " ('BROWN MICHAEL', (49288, 'NaN', 'NaN')),\n",
      " ('PEREIRA PAULO V. FERRAZ', (27942, 'NaN', 'NaN')),\n",
      " ('HAYES ROBERT E', (7961, 'NaN', 'NaN')),\n",
      " ('SAVAGE FRANK', (3750, 'NaN', 'NaN')),\n",
      " ('MEYER JEROME J', (2151, 'NaN', 'NaN')),\n",
      " ('BLAKE JR. NORMAN P', (1279, 'NaN', 'NaN')),\n",
      " ('HAUG DAVID L', (475, 'NaN', 'NaN')),\n",
      " ('MENDELSOHN JOHN', (148, 'NaN', 'NaN'))]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Starter code for exploring the Enron dataset (emails + finances);\n",
    "    loads up the dataset (pickled dict of dicts).\n",
    "\n",
    "    The dataset has the form:\n",
    "    enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "\n",
    "    {features_dict} is a dictionary of features associated with that person.\n",
    "    You should explore features_dict as part of the mini-project,\n",
    "    but here's an example to get you started:\n",
    "\n",
    "    enron_data[\"SKILLING JEFFREY K\"][\"bonus\"] = 5600000\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "import pprint as pp\n",
    "from poi_email_addresses import poiEmails\n",
    "import operator\n",
    "\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        import math\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "poi_emails = poiEmails()\n",
    "\n",
    "with open(\"../final_project/final_project_dataset.pkl\", \"r\") as f:\n",
    "    enron_data = pickle.load(f)\n",
    "    \n",
    "    poi = set()\n",
    "    for empl in enron_data:\n",
    "        if enron_data[empl]['poi'] == True:poi.add(empl)\n",
    "    \n",
    "    \n",
    "    top_of_asshole = dict()\n",
    "    hided_bitches = dict()\n",
    "    hided_bitches_and_POI = dict()\n",
    "    for asshole in enron_data:\n",
    "        if not isnan(enron_data[asshole]['total_payments']):\n",
    "            top_of_asshole[asshole] = (enron_data[asshole]['total_payments'],\\\n",
    "                                       enron_data[asshole]['salary'], enron_data[asshole]['bonus'])\n",
    "        elif enron_data[asshole]['poi'] == True:\n",
    "            hided_bitches[asshole] = enron_data[asshole]['total_payments']\n",
    "            hided_bitches_and_POI[asshole] = enron_data[asshole]['poi']\n",
    "        else: hided_bitches[asshole] = enron_data[asshole]['total_payments']\n",
    "    top_of_asshole = sorted(top_of_asshole.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    salary = dict()\n",
    "    mail = dict()\n",
    "    for empl in enron_data:\n",
    "        if not isnan(enron_data[empl]['salary']):\n",
    "            salary[empl] = enron_data[empl]['salary']\n",
    "        if not isnan(enron_data[empl]['email_address']):\n",
    "            mail[empl] = enron_data[empl]['email_address']\n",
    "    salary = sorted(salary.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    \n",
    "    print \"nb of empl. =\", len(enron_data)\n",
    "    print \"nb of field/empl. =\", len(enron_data['LAY KENNETH L'])\n",
    "    print \"nb of poi =\", len(poi)\n",
    "    print \"James Prentice / total stock value = \",\\\n",
    "        round(enron_data['PRENTICE JAMES']['total_stock_value'] / 10**6., 2), \"M$\"\n",
    "    print \"Wesley Colwell / from this person to poi = \",\\\n",
    "        enron_data['COLWELL WESLEY']['from_this_person_to_poi'], \"mails\"\n",
    "    print \"Jeffrey K Skilling / exercised stock options = \",\\\n",
    "        round(enron_data['SKILLING JEFFREY K']['exercised_stock_options'] / 10**6., 2), \"M$\"\n",
    "    print \"nb of empl. with salary = {}/{}, nb of empl. with email adress = {}/{}\"\\\n",
    "        .format(len(salary), len(enron_data), len(mail), len(enron_data))\n",
    "    print \"nb of empl. without To. pay. data = {}, %age = {}%\"\\\n",
    "        .format(len(hided_bitches), round((float(len(hided_bitches))/len(enron_data))*100, 2))\n",
    "    print \"nb of POI without To. pay. data = {}, %age = {}%\"\\\n",
    "        .format(len(hided_bitches_and_POI), round((float(len(hided_bitches_and_POI))/len(enron_data))*100, 2))\n",
    "    \n",
    "    \n",
    "    pp.pprint(top_of_asshole)\n",
    "    #pp.pprint(hided_bitches_and_POI)\n",
    "    #pp.pprint(enron_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PAS ENCORE UTILISE A VOIR EN LECON 7\n",
    "\n",
    "\"\"\" \n",
    "    A general tool for converting data from the\n",
    "    dictionary format to an (n x k) python list that's \n",
    "    ready for training an sklearn algorithm\n",
    "\n",
    "    n--no. of key-value pairs in dictonary\n",
    "    k--no. of features being extracted\n",
    "\n",
    "    dictionary keys are names of persons in dataset\n",
    "    dictionary values are dictionaries, where each\n",
    "        key-value pair in the dict is the name\n",
    "        of a feature, and its value for that person\n",
    "\n",
    "    In addition to converting a dictionary to a numpy \n",
    "    array, you may want to separate the labels from the\n",
    "    features--this is what targetFeatureSplit is for\n",
    "\n",
    "    so, if you want to have the poi label as the target,\n",
    "    and the features you want to use are the person's\n",
    "    salary and bonus, here's what you would do:\n",
    "\n",
    "    feature_list = [\"poi\", \"salary\", \"bonus\"] \n",
    "    data_array = featureFormat( data_dictionary, feature_list )\n",
    "    label, features = targetFeatureSplit(data_array)\n",
    "\n",
    "    the line above (targetFeatureSplit) assumes that the\n",
    "    label is the _first_ item in feature_list--very important\n",
    "    that poi is listed first!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True,\\\n",
    "                    remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "\n",
    "        return targets and features as separate lists\n",
    "\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
