{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SKLearn DT](https://scikit-learn.org/stable/modules/tree.html)\n",
    "\n",
    "\n",
    "[How to- SKLearn DTC](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "X = [[0, 0], [1, 1]]\n",
    "Y = [0, 1]\n",
    "\n",
    "clf = tree.DecisionTreeClassifier() #classifier\n",
    "clf = clf.fit(X, Y) #fit = entraînement via X (features) et Y (label)\n",
    "\n",
    "print(clf.predict([[2., 2.]])) #Prédiction basé sur l'entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representation graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "from prep_terrain_data import makeTerrainData\n",
    "from class_vis import prettyPicture\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "\n",
    "features_train, labels_train, features_test, labels_test = makeTerrainData()\n",
    "\n",
    "### the training data (features_train, labels_train) have both \"fast\" and \"slow\" points mixed\n",
    "### in together--separate them so we can give them different colors in the scatterplot,\n",
    "### and visually identify them\n",
    "grade_fast = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "bumpy_fast = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==0]\n",
    "grade_slow = [features_train[ii][0] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "bumpy_slow = [features_train[ii][1] for ii in range(0, len(features_train)) if labels_train[ii]==1]\n",
    "\n",
    "\n",
    "##############################\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 2)\n",
    "clf = clf.fit(features_train, labels_train)\n",
    "pred = clf.predict(features_test)\n",
    "acc = accuracy_score(labels_test, pred)\n",
    "\n",
    "clf2 = tree.DecisionTreeClassifier(min_samples_split = 50)\n",
    "clf2 = clf2.fit(features_train, labels_train)\n",
    "pred2 = clf2.predict(features_test)\n",
    "acc2 = accuracy_score(labels_test, pred2)\n",
    "\n",
    "##############################\n",
    "\n",
    "\n",
    "### draw the decision boundary with the text points overlaid\n",
    "prettyPicture(clf, features_test, labels_test, \"DT_Test1\")\n",
    "prettyPicture(clf2, features_test, labels_test, \"DT_Test2\")\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DT_Test1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DT_Test2.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Qu'est ce que c'est- Entropy & Information Gain](https://victorzhou.com/blog/information-gain/)\n",
    "\n",
    "<img src=\"http://chart.apis.google.com/chart?cht=tx&chl=E%3D-%5Csum_ip_i%5Clog_2p_i%20%2C\">\n",
    "\n",
    "<img src=\"Info. gain formula.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"E&IG exo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'obtenir l'information gain sur grade (\"Niveau de qualité\" d'un split DT), on considère d'abord l'entropie (= le bordel) des différents objets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.918295834054\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def ent_formula(moy_comp):\n",
    "    return(-moy_comp * math.log(moy_comp, 2))\n",
    "\n",
    "ent_parent = ent_formula(1/2.) + ent_formula(1/2.)\n",
    "print ent_parent\n",
    "#Entropie maximale car pas moyen de distinguer les classes (normal, on est au niveau du parent)\n",
    "\n",
    "ent_enfant_steep = ent_formula(2/3.) + ent_formula(1/3.)\n",
    "print ent_enfant_steep\n",
    "#Deux steep correspondent à slow, un steep correspond à fast\n",
    "\n",
    "ent_enfant_flat = 0\n",
    "print ent_enfant_flat\n",
    "#Un flat correspond à un fast, aucune entropie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on compare l'entropie parentale à l'entropie filiale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311278124459\n"
     ]
    }
   ],
   "source": [
    "inf_gain = ent_parent - (3/4. * ent_enfant_steep + 1/4. * ent_enfant_flat)\n",
    "print inf_gain\n",
    "#On multiplie par le ratio des valeurs dans la classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation suppl. : Si on fait le même exercice pour les classes bumpiness ou speed limit on obtient un information gain = 0 (bumpiness) ou 1 (speed limit). Soit elles dégradent totalement l'information de base, soit elles la confirment totalement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Différence entre Gini Index & Information Gain](https://towardsdatascience.com/decision-tree-fundamentals-388f57a60d2a)\n",
    "\n",
    "[Dilemne biais-variance](https://openclassrooms.com/fr/courses/4011851-initiez-vous-au-machine-learning/4092326-trouvez-le-bon-compromis-entre-biais-et-variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "training time: 5.699 s\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 3 (decision tree) mini-project.\n",
    "\n",
    "    Use a Decision Tree to identify emails from the Enron corpus by author:    \n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "    \n",
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "#########################################################\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split = 40)\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "t1 = time()\n",
    "print \"training time:\", round(t1-t0, 3), \"s\"\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "predict time: 0.005 s\n",
      "accuracy =  0.967007963595\n",
      "quant. features =  379 379\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "sys.path.append(\"../tools/\")\n",
    "from email_preprocess import preprocess\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### features_train and features_test are the features for the training\n",
    "### and testing datasets, respectively\n",
    "### labels_train and labels_test are the corresponding item labels\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "\n",
    "\n",
    "#########################################################\n",
    "\n",
    "t1 = time()\n",
    "pred = clf.predict(features_test)\n",
    "t2 = time()\n",
    "print \"predict time:\", round(t2-t1, 3), \"s\"\n",
    "\n",
    "print \"accuracy = \", accuracy_score(labels_test, pred)\n",
    "print \"quant. features = \", len(features_train[0]), len(features_test[0])\n",
    "#On peut modifier la ligne 'selector = SelectPercentile(f_classif, percentile= x )' dans tools/email_preprocess.py\n",
    "#Afin de modifier la quantité de features\n",
    "#Résultat sur la précision:\n",
    "#Précision (percentile = 10 / nb. de features = 3785) = 0.977815699659\n",
    "#Précision (percentile = 1 / nb. de features = 379) = 0.967007963595\n",
    "\n",
    "#########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
